use crate::models::document::{Document, ProcessingStatus};
use crate::services::{
    dashscope_embedding_service::DashScopeEmbeddingService,
    document_processor::DocumentProcessor,
    seekdb_adapter::{SeekDbAdapter, VectorDocument},
};
use anyhow::{anyhow, Result};
use uuid::Uuid;
use std::collections::HashMap;
use std::sync::Arc;
use tokio::sync::Mutex;

/// ç›¸ä¼¼æ–‡æ¡£å—ç»“æ„ï¼ˆç”¨äºèŠå¤©ä¸Šä¸‹æ–‡ï¼‰
#[derive(Debug, Clone)]
pub struct SimilarChunk {
    pub document_id: String,
    pub filename: Option<String>,
    pub content: String,
    pub relevance_score: f64,
}

pub struct DocumentService {
    documents: HashMap<Uuid, Document>,
    document_processor: DocumentProcessor,
    vector_db: Arc<Mutex<SeekDbAdapter>>,
    embedding_service: Arc<DashScopeEmbeddingService>,
}

impl DocumentService {
    pub async fn new() -> Result<Self> {
        // Use in-memory path for testing/temporary usage
        let temp_dir = std::env::temp_dir();
        let db_path = temp_dir.join("mine_kb_temp.db");
        let vector_db = Arc::new(Mutex::new(SeekDbAdapter::new(db_path)?));

        // ä»ç¯å¢ƒå˜é‡è¯»å– API Key
        let api_key = std::env::var("DASHSCOPE_API_KEY")
            .map_err(|_| anyhow!("æœªæ‰¾åˆ° DASHSCOPE_API_KEY ç¯å¢ƒå˜é‡"))?;
        let embedding_service = Arc::new(DashScopeEmbeddingService::new(api_key, None)?);

        Ok(Self {
            documents: HashMap::new(),
            document_processor: DocumentProcessor::new(),
            vector_db,
            embedding_service,
        })
    }

    pub async fn with_db_path(db_path: &str) -> Result<Self> {
        let vector_db = Arc::new(Mutex::new(SeekDbAdapter::new(db_path)?));

        let api_key = std::env::var("DASHSCOPE_API_KEY")
            .map_err(|_| anyhow!("æœªæ‰¾åˆ° DASHSCOPE_API_KEY ç¯å¢ƒå˜é‡"))?;
        let embedding_service = Arc::new(DashScopeEmbeddingService::new(api_key, None)?);

        Ok(Self {
            documents: HashMap::new(),
            document_processor: DocumentProcessor::new(),
            vector_db,
            embedding_service,
        })
    }

    pub async fn with_config(
        db_path: &str,
        api_key: String,
        base_url: Option<String>
    ) -> Result<Self> {
        Self::with_full_config(db_path, api_key, base_url, None).await
    }

    pub async fn with_full_config(
        db_path: &str,
        api_key: String,
        base_url: Option<String>,
        python_path: Option<&str>
    ) -> Result<Self> {
        log::info!("ğŸ—ï¸  [DOC-SERVICE] åˆå§‹åŒ–DocumentService, db_path: {}", db_path);
        let vector_db = Arc::new(Mutex::new(
            SeekDbAdapter::new_with_python(db_path, python_path.unwrap_or("python3"))?
        ));
        log::info!("ğŸ—ï¸  [DOC-SERVICE] æ•°æ®åº“å®ä¾‹å·²åˆ›å»º");

        log::info!("ğŸ¯ ä½¿ç”¨é˜¿é‡Œäº‘ç™¾ç‚¼ Embedding API (text-embedding-v2)");
        let embedding_service = Arc::new(DashScopeEmbeddingService::new(api_key, base_url)?);

        Ok(Self {
            documents: HashMap::new(),
            document_processor: DocumentProcessor::new(),
            vector_db,
            embedding_service,
        })
    }

    /// è·å–å‘é‡æ•°æ®åº“çš„å¼•ç”¨
    pub fn get_vector_db(&self) -> Arc<Mutex<SeekDbAdapter>> {
        self.vector_db.clone()
    }

    pub async fn add_document(
        &mut self,
        project_id: Uuid,
        file_path: String,
        file_size: u64,
        content_hash: String,
    ) -> Result<Uuid> {
        // Validate file before processing
        self.document_processor.validate_file(&file_path)?;

        // Create document
        let document = Document::new(project_id, file_path, file_size, content_hash)?;
        let document_id = document.id;

        // Store document
        self.documents.insert(document_id, document.clone());

        // Process document and create embeddings
        self.process_document_async(document_id).await?;

        Ok(document_id)
    }

    async fn process_document_async(&mut self, document_id: Uuid) -> Result<()> {
        let document = self.documents.get_mut(&document_id)
            .ok_or_else(|| anyhow!("Document not found: {}", document_id))?;

        // Update status to processing
        document.processing_status = ProcessingStatus::Processing;

        // Process the document
        match self.document_processor.process_document(document).await {
            Ok(processing_result) => {
                log::info!("Document processed successfully: {} chunks", processing_result.chunks.len());

                // Create vector documents for each chunk
                let mut vector_docs = Vec::new();
                let chunk_count = processing_result.chunks.len();

                // æ‰¹é‡ç”Ÿæˆ embeddingsï¼ˆæ›´é«˜æ•ˆï¼‰
                let chunk_texts: Vec<String> = processing_result.chunks
                    .iter()
                    .map(|c| c.content.clone())
                    .collect();

                let embeddings = self.embedding_service.embed_batch(&chunk_texts).await?;

                for (chunk, embedding) in processing_result.chunks.iter().zip(embeddings.iter()) {

                        let vector_doc = VectorDocument {
                            id: Uuid::new_v4().to_string(),
                            project_id: document.project_id.to_string(),
                            document_id: document.id.to_string(),
                            chunk_index: chunk.chunk_index as i32,
                            content: chunk.content.clone(),
                            embedding: embedding.clone(),
                            metadata: {
                                let mut meta = HashMap::new();
                                meta.insert("filename".to_string(), document.filename.clone());
                                meta.insert("mime_type".to_string(), document.mime_type.clone());
                                meta.insert("start_offset".to_string(), chunk.start_offset.to_string());
                                meta.insert("end_offset".to_string(), chunk.end_offset.to_string());
                                meta
                            },
                        };
                        vector_docs.push(vector_doc);
                    }

                // Store vectors in database
                {
                    let mut db = self.vector_db.lock().await;
                    db.add_documents(vector_docs)?;
                }

                // Update document status
                document.processing_status = ProcessingStatus::Indexed;
                document.chunk_count = chunk_count as u32;
                document.processed_at = Some(chrono::Utc::now());

                log::info!("Document indexed successfully: {}", document.filename);
            }
            Err(e) => {
                log::error!("Document processing failed: {}", e);
                document.processing_status = ProcessingStatus::Failed;
                document.error_message = Some(e.to_string());
                return Err(e);
            }
        }

        Ok(())
    }

    pub fn get_document(&self, document_id: Uuid) -> Option<&Document> {
        self.documents.get(&document_id)
    }

    pub fn get_document_mut(&mut self, document_id: Uuid) -> Option<&mut Document> {
        self.documents.get_mut(&document_id)
    }

    pub async fn search_documents(
        &self,
        query: &str,
        project_id: Option<Uuid>,
        limit: usize,
    ) -> Result<Vec<crate::services::seekdb_adapter::SearchResult>> {
        let query_embedding = self.embedding_service.embed_text(query).await?;
        let project_id_str = project_id.map(|id| id.to_string());

        let db = self.vector_db.lock().await;

        // ä½¿ç”¨ DashScope embeddingï¼Œç›¸ä¼¼åº¦é€šå¸¸åœ¨ 0.5-0.9 ä¹‹é—´
        let results = db.similarity_search(
            &query_embedding,
            project_id_str.as_deref(),
            limit,
            0.5, // DashScope embedding è´¨é‡é«˜ï¼Œå¯ä»¥è®¾ç½®è¾ƒé«˜é˜ˆå€¼
        )?;

        Ok(results)
    }

    /// ä½¿ç”¨æ··åˆæ£€ç´¢æœç´¢ç›¸å…³æ–‡æ¡£å—ï¼ˆå‘é‡+å…¨æ–‡ï¼Œç”¨äºèŠå¤©ä¸Šä¸‹æ–‡ï¼‰
    pub async fn search_similar_chunks_hybrid(
        &self,
        project_id: &str,
        query: &str,
        top_k: usize,
    ) -> Result<Vec<SimilarChunk>> {
        log::info!("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");
        log::info!("ğŸ” [HYBRID-SEARCH] å¼€å§‹æ··åˆæ£€ç´¢æ–‡æ¡£å—");
        log::info!("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");
        log::info!("ğŸ“‹ é¡¹ç›®ID: {}", project_id);
        log::info!("ğŸ’¬ æŸ¥è¯¢å†…å®¹: {}", query);
        log::info!("ğŸ“Š è¿”å›æ•°é‡: {}", top_k);

        // ä½¿ç”¨ DashScope API ç”ŸæˆæŸ¥è¯¢å‘é‡
        log::info!("ğŸŒ è°ƒç”¨ DashScope Embedding API...");
        let query_embedding = self.embedding_service.embed_text(query).await?;
        log::info!("âœ… ç”ŸæˆæŸ¥è¯¢å‘é‡æˆåŠŸï¼Œç»´åº¦: {}", query_embedding.len());

        // ä»å‘é‡æ•°æ®åº“æ‰§è¡Œæ··åˆæœç´¢
        let db = self.vector_db.lock().await;

        log::info!("ğŸ”„ æ‰§è¡Œæ··åˆæ£€ç´¢ï¼ˆè¯­ä¹‰æƒé‡=0.7ï¼‰...");

        // ä½¿ç”¨æ··åˆæ£€ç´¢ (è¯­ä¹‰æƒé‡ 0.7 è¡¨ç¤ºæ›´åé‡å‘é‡ç›¸ä¼¼åº¦)
        let results = db.hybrid_search(
            query,
            &query_embedding,
            Some(project_id),
            top_k,
            0.7, // semantic boost: 0.7 è¡¨ç¤ºå‘é‡æ£€ç´¢å  70% æƒé‡
        )?;

        log::info!("âœ… æ··åˆæ£€ç´¢å®Œæˆï¼Œæ‰¾åˆ° {} ä¸ªç»“æœ", results.len());

        // æ‰“å°æ‰€æœ‰ç»“æœçš„è¯¦ç»†ä¿¡æ¯
        for (i, result) in results.iter().enumerate() {
            let preview = result.document.content.chars().take(80).collect::<String>();
            log::info!("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");
            log::info!("ğŸ“„ ç»“æœ #{}", i + 1);
            log::info!("   ğŸ”¢ åˆ†æ•°: {:.4}", result.similarity);
            log::info!("   ğŸ“ å†…å®¹é¢„è§ˆ: {}...", preview);
            log::info!("   ğŸ“‚ æ–‡æ¡£ID: {}", result.document.document_id);
            log::info!("   ğŸ”– å—ç´¢å¼•: {}", result.document.chunk_index);
        }

        // è½¬æ¢ä¸º SimilarChunk
        let chunks: Vec<SimilarChunk> = results
            .iter()
            .map(|result| {
                // ä» metadata ä¸­è·å– filename
                let filename = result.document.metadata
                    .get("filename")
                    .cloned();

                log::debug!("æ–‡æ¡£ {} çš„ filename: {:?}", result.document.document_id, filename);

                SimilarChunk {
                    document_id: result.document.document_id.clone(),
                    filename,
                    content: result.document.content.clone(),
                    relevance_score: result.similarity,
                }
            })
            .collect();

        log::info!("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");
        log::info!("âœ… [HYBRID-SEARCH] æ··åˆæ£€ç´¢å®Œæˆï¼Œè¿”å› {} ä¸ªç›¸å…³æ–‡æ¡£å—", chunks.len());
        log::info!("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");

        Ok(chunks)
    }

    // æœç´¢ç›¸å…³æ–‡æ¡£å—ï¼ˆç”¨äºèŠå¤©ä¸Šä¸‹æ–‡ï¼‰- ä¿ç•™çº¯å‘é‡æœç´¢ä½œä¸ºå¤‡é€‰
    pub async fn search_similar_chunks(
        &self,
        project_id: &str,
        query: &str,
        top_k: usize,
    ) -> Result<Vec<SimilarChunk>> {
        log::info!("ğŸ” å¼€å§‹æœç´¢ç›¸å…³æ–‡æ¡£å—: project_id={}, query={}, top_k={}", project_id, query, top_k);

        // ä½¿ç”¨ DashScope API ç”ŸæˆæŸ¥è¯¢å‘é‡
        let query_embedding = self.embedding_service.embed_text(query).await?;
        log::info!("âœ… ç”ŸæˆæŸ¥è¯¢å‘é‡æˆåŠŸï¼Œç»´åº¦: {}", query_embedding.len());

        // ä»å‘é‡æ•°æ®åº“æœç´¢
        let db = self.vector_db.lock().await;

        log::info!("ğŸ” ä½¿ç”¨SeekDBå‘é‡æ£€ç´¢ï¼Œé˜ˆå€¼=0.3");

        // ä½¿ç”¨ DashScope embeddingï¼Œç›¸ä¼¼åº¦é€šå¸¸åœ¨ 0.3-0.9 ä¹‹é—´
        // 0.3 ä½œä¸ºé˜ˆå€¼å¯ä»¥è·å¾—è¾ƒå®½æ³›ä½†ç›¸å…³çš„ç»“æœ
        let results = db.similarity_search(
            &query_embedding,
            Some(project_id),
            top_k,
            0.3, // DashScope embedding: 0.3=å®½æ³›, 0.4=ä¸­ç­‰, 0.5+=ä¸¥æ ¼
        )?;

        log::info!("âœ… å‘é‡æœç´¢å®Œæˆï¼ˆé˜ˆå€¼=0.3ï¼‰ï¼Œæ‰¾åˆ° {} ä¸ªç»“æœ", results.len());

        // æ‰“å°å‰å‡ ä¸ªç»“æœçš„ç›¸ä¼¼åº¦åˆ†æ•°
        for (i, result) in results.iter().take(3).enumerate() {
            log::info!("  ğŸ“„ ç»“æœ#{}: ç›¸ä¼¼åº¦={:.4}, å†…å®¹é¢„è§ˆ={}",
                i + 1,
                result.similarity,
                &result.document.content.chars().take(50).collect::<String>()
            );
        }

        // è½¬æ¢ä¸º SimilarChunk
        let chunks: Vec<SimilarChunk> = results
            .iter()
            .map(|result| {
                // ä» metadata ä¸­è·å– filename
                let filename = result.document.metadata
                    .get("filename")
                    .cloned();

                log::debug!("æ–‡æ¡£ {} çš„ filename: {:?}", result.document.document_id, filename);

                SimilarChunk {
                    document_id: result.document.document_id.clone(),
                    filename,
                    content: result.document.content.clone(),
                    relevance_score: result.similarity,
                }
            })
            .collect();

        Ok(chunks)
    }

    pub fn list_documents(&self, project_id: Option<Uuid>) -> Vec<&Document> {
        self.documents
            .values()
            .filter(|doc| {
                if let Some(pid) = project_id {
                    doc.project_id == pid
                } else {
                    true
                }
            })
            .collect()
    }

    pub fn delete_document(&mut self, document_id: Uuid) -> Result<()> {
        let _document = self.documents
            .remove(&document_id)
            .ok_or_else(|| anyhow!("Document not found: {}", document_id))?;

        // TODO: Delete from vector database
        // self.vector_db.delete_documents(&collection_name, &[document_id.to_string()]).await?;

        Ok(())
    }

    pub fn get_documents_by_status(&self, status: ProcessingStatus) -> Vec<&Document> {
        self.documents
            .values()
            .filter(|doc| doc.processing_status == status)
            .collect()
    }

    pub fn update_document_status(
        &mut self,
        document_id: Uuid,
        status: ProcessingStatus,
        error_message: Option<String>,
    ) -> Result<()> {
        let document = self.documents
            .get_mut(&document_id)
            .ok_or_else(|| anyhow!("Document not found: {}", document_id))?;

        document.update_processing_status(status, error_message);
        Ok(())
    }

    pub async fn reprocess_document(&mut self, document_id: Uuid) -> Result<()> {
        let document = self.documents
            .get_mut(&document_id)
            .ok_or_else(|| anyhow!("Document not found: {}", document_id))?;

        // Reset status to processing
        document.update_processing_status(ProcessingStatus::Processing, None);

        // Reprocess
        self.process_document_async(document_id).await
    }


    pub async fn count_documents(&self, project_id: Option<Uuid>) -> usize {
        // ä»æ•°æ®åº“æŸ¥è¯¢å®é™…çš„æ–‡æ¡£æ•°é‡ï¼Œè€Œä¸æ˜¯ä»å†…å­˜ç»Ÿè®¡
        // è¿™æ ·å¯ä»¥ç¡®ä¿ç»Ÿè®¡çš„æ˜¯ç´¯åŠ çš„æ€»æ•°ï¼Œè€Œä¸æ˜¯å½“å‰æ‰¹æ¬¡çš„æ•°é‡
        if let Some(pid) = project_id {
            let db = self.vector_db.lock().await;
            match db.count_project_documents(&pid.to_string()) {
                Ok(count) => count,
                Err(e) => {
                    log::error!("ä»æ•°æ®åº“ç»Ÿè®¡æ–‡æ¡£æ•°é‡å¤±è´¥: {}", e);
                    // é™çº§åˆ°å†…å­˜ç»Ÿè®¡
                    self.documents
                        .values()
                        .filter(|doc| doc.project_id == pid)
                        .count()
                }
            }
        } else {
            // å¦‚æœæ²¡æœ‰æŒ‡å®šé¡¹ç›®ï¼Œä½¿ç”¨å†…å­˜ç»Ÿè®¡
            self.documents.len()
        }
    }

    pub fn get_processing_stats(&self, project_id: Option<Uuid>) -> HashMap<ProcessingStatus, usize> {
        let mut stats = HashMap::new();

        let documents = if let Some(pid) = project_id {
            self.documents.values().filter(|doc| doc.project_id == pid).collect::<Vec<_>>()
        } else {
            self.documents.values().collect::<Vec<_>>()
        };

        for document in documents {
            *stats.entry(document.processing_status.clone()).or_insert(0) += 1;
        }

        stats
    }

    pub fn is_supported_file(&self, file_path: &str) -> bool {
        self.document_processor.is_supported_file(file_path)
    }

    pub fn get_supported_extensions() -> Vec<&'static str> {
        DocumentProcessor::get_supported_extensions()
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    fn create_test_service() -> DocumentService {
        let vector_db = VectorDbService::new("localhost", 8000);
        DocumentService::new(vector_db)
    }

    #[test]
    fn test_document_service_creation() {
        let service = create_test_service();
        assert_eq!(service.documents.len(), 0);
    }

    #[tokio::test]
    async fn test_add_document() {
        let mut service = create_test_service();
        let project_id = Uuid::new_v4();

        // This would fail in a real test because the file doesn't exist
        // In a real implementation, you'd mock the file system
        let result = service.add_document(
            project_id,
            "/non/existent/file.txt".to_string(),
            1024,
            "hash123".to_string(),
        ).await;

        // Should fail because file doesn't exist
        assert!(result.is_err());
    }

    #[test]
    fn test_list_documents_by_project() {
        let service = create_test_service();
        let project_id = Uuid::new_v4();

        let documents = service.list_documents(Some(project_id));
        assert_eq!(documents.len(), 0);

        let all_documents = service.list_documents(None);
        assert_eq!(all_documents.len(), 0);
    }

    #[test]
    fn test_supported_file_check() {
        let service = create_test_service();

        assert!(service.is_supported_file("test.txt"));
        assert!(service.is_supported_file("test.md"));
        assert!(service.is_supported_file("test.pdf"));
        assert!(!service.is_supported_file("test.exe"));
    }

    #[test]
    fn test_processing_stats() {
        let service = create_test_service();
        let stats = service.get_processing_stats(None);
        assert!(stats.is_empty());
    }

    #[test]
    fn test_get_supported_extensions() {
        let extensions = DocumentService::get_supported_extensions();
        assert!(extensions.contains(&"txt"));
        assert!(extensions.contains(&"md"));
        assert!(extensions.contains(&"pdf"));
    }
}
